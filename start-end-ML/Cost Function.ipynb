{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9ef315",
   "metadata": {},
   "source": [
    "# Cost function\n",
    "\n",
    "- In machine learning, a cost function (also known as a **loss function** or objective function) is a measure of how well a model performs with respect to its given training data and the expected output. \n",
    "- The cost function `quantifies the difference between the predicted values of the model and the actual target values in the training data`.\n",
    "- The primary `goal in machine learning is to minimize this cost function`, as it reflects the error or loss of the model's predictions. By minimizing the cost function, the model learns to make more accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7f3899",
   "metadata": {},
   "source": [
    "The choice of the cost function depends on the specific problem being solved and the type of machine learning algorithm being used. For example:\n",
    "\n",
    "- **Mean Squared Error (MSE):**\n",
    "    - Problem Type: Regression\n",
    "    - Algorithms: Linear Regression, Neural Networks\n",
    "\n",
    "- **Mean Absolute Error (MAE):**\n",
    "    - Problem Type: Regression\n",
    "    - Algorithms: Linear Regression, Decision Trees\n",
    "\n",
    "- **Log Loss (Cross-Entropy Loss):**\n",
    "    - Problem Type: Binary Classification, Multi-class Classification\n",
    "    - Algorithms: Logistic Regression, Neural Networks (with softmax activation), Gradient Boosting Machines (GBMs)\n",
    "\n",
    "- **Hinge Loss:**\n",
    "    - Problem Type: Binary Classification\n",
    "    - Algorithms: Support Vector Machines (SVMs), SVM-based classifiers like Linear SVM and Kernel SVM\n",
    "\n",
    "- **Squared Hinge Loss:**\n",
    "    - Problem Type: Binary Classification\n",
    "    - Algorithms: Support Vector Machines (SVMs)\n",
    "\n",
    "- **Binary Cross-Entropy Loss:**\n",
    "    - Problem Type: Binary Classification\n",
    "    - Algorithms: Neural Networks (binary classification), Logistic Regression\n",
    "\n",
    "- **Categorical Cross-Entropy Loss:**\n",
    "    - Problem Type: Multi-class Classification\n",
    "    - Algorithms: Neural Networks (multi-class classification)\n",
    "\n",
    "- **Sparse Categorical Cross-Entropy Loss:**\n",
    "    - Problem Type: Multi-class Classification\n",
    "    - Algorithms: Neural Networks (multi-class classification) with sparse labels\n",
    "\n",
    "- **Kullback-Leibler Divergence (KL Divergence):**\n",
    "    - Problem Type: Probability Distributions (used in probabilistic models)\n",
    "    - Algorithms: Variational Autoencoders (VAEs)\n",
    "    \n",
    "The choice of cost function often depends on factors such as the problem domain, the distribution of the data, and the desired properties of the model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757d057",
   "metadata": {},
   "source": [
    "Minimizing the cost function is crucial in improving the accuracy of predictions made by a model. There are several techniques available to minimize the cost function during the training process:\n",
    "\n",
    "1. **Gradient Descent:**\n",
    "    - Gradient descent is a first-order optimization algorithm used to find the minimum of a function (in this case, the cost function).\n",
    "    - It works by iteratively moving in the direction of the steepest descent of the cost function with respect to the model parameters.\n",
    "    - There are different variants of gradient descent, including batch gradient descent, stochastic gradient descent (SGD), mini-batch gradient descent, and more advanced methods like Adam, RMSProp, and AdaGrad.\n",
    "\n",
    "2. **Backpropagation:**\n",
    "    - Backpropagation is a technique used to compute the gradients of the cost function with respect to the parameters of the model.\n",
    "    - It efficiently calculates these gradients by propagating them backwards through the network, from the output layer to the input layer.\n",
    "    - Backpropagation is typically used in conjunction with gradient descent for optimizing neural network models.\n",
    "\n",
    "3. **Learning Rate Scheduling:**\n",
    "    - Adjusting the learning rate during training can help improve convergence and prevent overshooting or oscillation around the minimum.\n",
    "    - Techniques such as learning rate decay, step decay, exponential decay, and adaptive learning rates (e.g., Adam) are commonly used to schedule the learning rate.\n",
    "\n",
    "4. **Regularization:**\n",
    "    - Regularization techniques such as L1 regularization (Lasso), L2 regularization (Ridge), and Elastic Net regularization are used to prevent overfitting by penalizing large parameter values.\n",
    "    - These techniques add a regularization term to the cost function, encouraging the model to learn simpler patterns that generalize better to unseen data.\n",
    "\n",
    "5. **Early Stopping:**\n",
    "    - Early stopping involves monitoring the validation error during training and stopping the training process when the validation error stops improving.\n",
    "    - This prevents overfitting by halting training before the model starts to memorize the training data.\n",
    "\n",
    "6. **Ensemble Methods:**\n",
    "    - Ensemble methods combine multiple models to improve predictive performance.\n",
    "    - Techniques such as bagging, boosting, and stacking can be used to combine the predictions of multiple models trained on different subsets of the data or with different algorithms.\n",
    "\n",
    "7. **Batch Normalization:**\n",
    "    - Batch normalization is a technique used to improve the training speed and stability of neural networks by normalizing the inputs of each layer.\n",
    "    - It helps mitigate the effects of vanishing or exploding gradients during training.\n",
    "\n",
    "8. **Data Augmentation:**\n",
    "    - Data augmentation involves generating new training samples by applying transformations such as rotation, translation, scaling, and flipping to the existing training data.\n",
    "    - This helps increase the diversity of the training data and improve the generalization ability of the model.\n",
    "\n",
    "By employing these techniques, practitioners can effectively minimize the cost function during the training process, leading to more accurate predictions and better-performing machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9866b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01880a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c79d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e98a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae29cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc506adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834d0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe46f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3992b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d692e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5487c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e5e8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287bebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b6ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c54c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b533e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e7254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416b116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581d2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ff45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8654a03c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e529a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28797444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a23495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed912e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6039536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18287a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bcf16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fec112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040f163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7bdef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928b7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef6723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd8a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c543d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e6f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41070a89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c79bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec6aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa427697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5dd0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398afa05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
