{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d311d3f",
   "metadata": {},
   "source": [
    "# What is Machine Learning?\n",
    "\n",
    "Machine Learning is a field of AI that focuses on the development of algorithms and statistical models that enable computers to improve their performance on a task through experience or data, without being explicitly programmed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7034b92a",
   "metadata": {},
   "source": [
    "# Difference between supervised and unsupervused learning?\n",
    "\n",
    "In supervised learning, algorithm is trained on a labelled dataset, where each input is associated with its corresponding output. In unsupervised learning, algorithm is given unlabelled data and must find patterns or relationships within the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff21c0",
   "metadata": {},
   "source": [
    "# What is bias-variance tradeoff?\n",
    "\n",
    "The bias-variance tradeoff is a key concept in ML that involves balancing the model's ability to fit the training data(low bias) and generalize to new, unseen data(low variance). High bias can lead to underfitting, and high variance can lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb6a234",
   "metadata": {},
   "source": [
    "# Explain feature engineering in ML\n",
    "\n",
    "Feature engineering is the process of selecting, transforming, or creating features(input variables) for a ML model to improve its performance. It involves extracting relevant information from the data to enhance the model's ability to learn patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d6023",
   "metadata": {},
   "source": [
    "# What is difference between classification and regression?\n",
    "\n",
    "Classification involves predicting a categorical outcome or label, while regression involves predicting a contiinuous numerical outcome. For example, predicting whther an email is spam(classification) versus preedicting the price of house(regression). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09278ba7",
   "metadata": {},
   "source": [
    "# What is overfitting in ML?\n",
    "\n",
    "Overfitting occurs when a model learns the training data too well, capturing noise and patterns that don't generalize to new data. It results in a model that performs poorly on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7bff9",
   "metadata": {},
   "source": [
    "# How does decision tree works?\n",
    "\n",
    "A decison tree is a hierarchical tree-like structure where each internal node represents a decision based onfeature, each branch represents the outcome of the decision, and each leaf node represents the final prediction or class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca6d75",
   "metadata": {},
   "source": [
    "# Explain the concept of cross-validation\n",
    "\n",
    "Cross-validation is a technique used to assess the performance of ML model by dividing datset into multiple subsets. The model is trained on some subsets and evaluated on others, providing a more robust estimate of its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdd536",
   "metadata": {},
   "source": [
    "# What is the purpose of regularization in ML?\n",
    "\n",
    "Regularization is a technique used to prevent overfitting by adding a penalty term to the model's cost function. It discourages the model from fitting the training data too closely and helps improve its generalization to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef534ea",
   "metadata": {},
   "source": [
    "# What is difference between precision and recall?\n",
    "\n",
    "Precision is the ratio of true positive predictions to the total number of positive predictions, while recall is the ratio of true positive predictions to the total number of actual positive instances. \n",
    "\n",
    "Precision focuses on the accuracy of positive predictions, while recall focuses on capturing all positive instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8416c",
   "metadata": {},
   "source": [
    "# What is Backward Elimination?\n",
    "Backward elimination is a feature selection technique while building a machine learning model. It is used to remove those features that do not have a significant effect on the dependent variable or prediction of output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83922185",
   "metadata": {},
   "source": [
    "# Explain the KNN algorithm\n",
    "\n",
    "KNN is a simple, instance based learning alogorithm where new data point is classified based on the majority of classes of its k-nearest neighbors in the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66b6d13",
   "metadata": {},
   "source": [
    "# What is the purpose of training set and testing set in ML?\n",
    "\n",
    "The training set is used to train ML model, and testing set is used to evaluate its performance. The separation helps assess how well the model generalizes to new, unseen data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028f6fe",
   "metadata": {},
   "source": [
    "# Differentiate between batch learning and online learning\n",
    "\n",
    "Batch learning invoves training the model on entire dataset at once, while online learning involves updating the model continuously as new data becomes available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df325de",
   "metadata": {},
   "source": [
    "# What is hyperparameters in ML?\n",
    "\n",
    "Hyperparamteres are external configurations for a ML model that are set before the training process. Example inludes learning rate, regularization strengths, and the number of hidden layer in neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfb5fef",
   "metadata": {},
   "source": [
    "# What is the purpose of confusion matrix?\n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of classifcation algorithm by presenting the counts of true positve, true negative, false postive, and false negative predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018353e",
   "metadata": {},
   "source": [
    "# What is difference between bagging and boosting?\n",
    "\n",
    "Bagging(Bootstrap Aggregating) involves training mutiple instances of same learning algorithm on different subsets of training data and combining their predictions. Boosting on other hand focuses on training multiple weak learners sequentially, with each learner correcting the errors of its predecessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa5148",
   "metadata": {},
   "source": [
    "# Explain the concept of dimensionality reduction?\n",
    "\n",
    "A dimensionality reduction is the process of reducing the number of input features in a dataset while retaining its essential information. It helps address the curse of dimensionality and can improve the performance of ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47886120",
   "metadata": {},
   "source": [
    "# What is the purpose of ROC curve?\n",
    "\n",
    "The Receiver Operating Characteristics(ROC) curve is a graphical representataion of a classification model's performance acorss different discrimination thresholds. It illustrates the trade-off between true positive rate(sensitivity) and false positive rate(1-specificity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8144f",
   "metadata": {},
   "source": [
    "# What is activation function in newural networks?\n",
    "\n",
    "Activation functions introduce non-linearity into neural networks, allowing them to learn complex patterns and relationships in data. Common activation functions include sigmoid, tanh, and rectified linear unit(ReLU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9271e",
   "metadata": {},
   "source": [
    "# Explain the bias-variance tradeoff in ontext of model complexity\n",
    "\n",
    "The bias-variance tradeoff refers to the tradeoff between the bias(error introduced by approximating a real world problem) and variance(model sensitivity to small fluctuations in the training data). As model complexity increases, bias decreases but variance increases, and finding the right balance is crucial for model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0099f7-fda2-401b-8c4a-ff98b797444c",
   "metadata": {},
   "source": [
    "# What is the purpose of the F1 score?\n",
    "\n",
    "The F1 score is a metric that combines precision and recall into a single value. It is particularly useful in situations where there is an uneven class distribution.\n",
    "\n",
    "# Explain the concept of ensemble learning.\n",
    "\n",
    "Ensemble learning involves combining multiple machine learning models to create a stronger, more robust model. Common techniques include bagging, boosting, and stacking.\n",
    "\n",
    "# What is the curse of dimensionality?\n",
    "\n",
    "The curse of dimensionality refers to the challenges and limitations that arise when dealing with high-dimensional data. As the number of features increases, the amount of data required to generalize well also increases exponentially.\n",
    "\n",
    "# How does the k-means clustering algorithm work?\n",
    "\n",
    "K-means is an unsupervised clustering algorithm that partitions a dataset into k clusters. It iteratively assigns data points to the nearest cluster center and updates the center based on the mean of the assigned points.\n",
    "\n",
    "# What is the difference between bagging and boosting?\n",
    "\n",
    "Bagging involves training multiple instances of the same learning algorithm on different subsets of the training data and combining their predictions. Boosting focuses on training multiple weak learners sequentially, with each learner correcting the errors of its predecessor.\n",
    "\n",
    "# Explain the concept of bias in machine learning.\n",
    "\n",
    "Bias in machine learning refers to the error introduced by approximating a real-world problem. High bias can result in underfitting, where the model is too simple to capture the underlying patterns in the data.\n",
    "\n",
    "# What is the purpose of a learning rate in optimization algorithms?\n",
    "\n",
    "The learning rate determines the step size at each iteration of the optimization process. It is a hyperparameter that influences the convergence and stability of optimization algorithms.\n",
    "\n",
    "# How does the support vector machine (SVM) algorithm work?\n",
    "\n",
    "SVM is a supervised machine learning algorithm used for classification and regression tasks. It works by finding a hyperplane that best separates the data into different classes, maximizing the margin between the classes.\n",
    "\n",
    "# What is cross-entropy loss, and when is it used?\n",
    "\n",
    "Cross-entropy loss, also known as log loss, is a measure of the performance of a classification model whose output is a probability value between 0 and 1. It is commonly used as a loss function in logistic regression and neural networks.\n",
    "\n",
    "# Explain the concept of transfer learning.\n",
    "\n",
    "Transfer learning involves using a pre-trained model on one task as the starting point for a model on a new, related task. This approach leverages knowledge gained from the first task to improve performance on the second task.\n",
    "\n",
    "# What is the purpose of dropout in neural networks?\n",
    "\n",
    "Dropout is a regularization technique used in neural networks to prevent overfitting. During training, random neurons are \"dropped out\" (ignored) with a certain probability, forcing the network to rely on a diverse set of features.\n",
    "\n",
    "# What is the difference between precision and recall?\n",
    "\n",
    "Precision is the ratio of true positive predictions to the total number of positive predictions, while recall is the ratio of true positive predictions to the total number of actual positive instances. Precision focuses on the accuracy of positive predictions, while recall focuses on capturing all positive instances.\n",
    "\n",
    "# How does the gradientdescent optimization algorithm work?\n",
    "\n",
    "Gradient descent is an optimization algorithm used to minimize the cost or loss function in machine learning models. It iteratively adjusts the model parameters in the direction opposite to the gradient of the cost function.\n",
    "\n",
    "# What is the role of regularization in neural networks?\n",
    "\n",
    "Regularization in neural networks involves adding a penalty term to the cost function to prevent overfitting. Common regularization techniques include L1 and L2 regularization, dropout, and early stopping.\n",
    "\n",
    "# Explain the concept of word embeddings in natural language processing.\n",
    "\n",
    "Word embeddings are vector representations of words in a continuous vector space. They capture semantic relationships between words and are commonly used in natural language processing tasks such as text classification and sentiment analysis.\n",
    "\n",
    "# What is a confusion matrix, and how is it used in machine learning?\n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification algorithm by presenting the counts of true positive, true negative, false positive, and false negative predictions. It is a useful tool for evaluating the performance of a model.\n",
    "\n",
    "# What is the purpose of the term \"one-hot encoding\" in machine learning?\n",
    "\n",
    "One-hot encoding is a technique used to represent categorical variables as binary vectors. Each category is assigned a unique binary code, and the entire set of categories is represented as a binary matrix.\n",
    "\n",
    "# Explain the concept of hyperparameter tuning.\n",
    "\n",
    "Hyperparameter tuning involves selecting the best values for the hyperparameters of a machine learning model to improve its performance. It is typically done using techniques such as grid search or random search.\n",
    "\n",
    "# How does the Naive Bayes algorithm work?\n",
    "\n",
    "Naive Bayes is a probabilistic algorithm based on Bayes's theorem. It assumes that features are conditionally independent given the class label, making computations more manageable. It is commonly used for text classification.\n",
    "\n",
    "# What is the purpose of the term \"bag of words\" in natural language processing?\n",
    "\n",
    "The bag of words model represents a document as an unordered set of words, disregarding grammar and word order but keeping track of word frequency. It is commonly used for text representation in natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f26176-2387-4692-9b0b-806de5260e08",
   "metadata": {},
   "source": [
    "# What is the difference between precision and accuracy?\n",
    "\n",
    "Precision is the ratio of true positive predictions to the total number of positive predictions, while accuracy is the ratio of correct predictions to the total number of predictions. Accuracy considers both true positives and true negatives.\n",
    "\n",
    "# How does the Random Forest algorithm work?\n",
    "\n",
    "Random Forest is an ensemble learning algorithm that builds multiple decision trees during training. It aggregates their predictions to improve accuracy and control overfitting. Each tree is trained on a subset of the data and features.\n",
    "\n",
    "# Explain the concept of batch normalization.\n",
    "\n",
    "Batch normalization is a technique used in neural networks to normalize the inputs of each layer, making the network more stable and accelerating training. It normalizes the input of a layer by adjusting and scaling the activations.\n",
    "\n",
    "# What is the purpose of the term \"precision- recall tradeoff\"?\n",
    "\n",
    "The precision-recall tradeoff refers to the inverse relationship between precision and recall in binary classification problems. As one metric improves, the other may decrease. It highlights the need to find a balance between precision and recall based on the problem's requirements.\n",
    "\n",
    "# What is the difference between bagging and stacking?\n",
    "\n",
    "Bagging (Bootstrap Aggregating) combines predictions from multiple models trained on different subsets of the data. Stacking, on the other hand, involves training multiple models and combining their predictions using another model (meta-model).\n",
    "\n",
    "# Explain the concept of feature scaling.\n",
    "\n",
    "Feature scaling is the process of standardizing or normalizing the numerical features of a dataset to bring them to a common scale. It ensures that no feature dominates others, particularly in algorithms sensitive to scale, like gradient-based optimization.\n",
    "\n",
    "# What is the purpose of the term \"dropout\" in neural networks?\n",
    "\n",
    "Dropout is a regularization technique used in neural networks to prevent overfitting. During training, random neurons are \"dropped out\" (ignored) with a certain probability, forcing the network to rely on a diverse set of features.\n",
    "\n",
    "# How does the k-fold cross-validation technique work?\n",
    "\n",
    "K-fold cross-validation divides the dataset into k subsets (folds). The model is trained k times, each time using k- 1 folds for training and the remaining fold for validation. This process is repeated with a different fold as the validation set in each iteration.\n",
    "\n",
    "# What is the purpose of the term \"precision at K\" in recommendation systems?\n",
    "\n",
    "Precision at K is a metric used in recommendation systems to evaluate the precision of the top-K ranked items recommended to a user. It measures the proportion of relevant items among the top-K recommendations.\n",
    "\n",
    "# Explain the concept of an ROC curve.\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation of a classification model's performance across different discrimination thresholds. It illustrates the trade-off between true positive rate (sensitivity) and false positive rate (1-specificity).\n",
    "\n",
    "# How does the term \"latent variable\" relate to factor analysis?\n",
    "\n",
    "In factor analysis, a latent variable is an unobservable variable that represents an underlying factor influencing the observed variables. It helps explain the correlation structure among observed variables.\n",
    "\n",
    "# What is the purpose of the term \"cross- entropy loss\" in neural networks?\n",
    "\n",
    "Cross-entropy loss, also known as log loss, is a measure of the performance of a classification model whose output is a probability value between 0 and 1. It quantifies the difference between predicted and actual probability distributions.\n",
    "\n",
    "# How does the term \"embedding layer\" function in neural networks?\n",
    "\n",
    "An embedding layer in neural networks is used to represent categorical variables as continuous vectors. It learns a dense representation of categories during training, which can capture semantic relationships between categories.\n",
    "\n",
    "# Explain the concept of hyperparameter tuning.\n",
    "\n",
    "Hyperparameter tuning involves selecting the best values for the hyperparameters of a machine learning model to improve its performance. It is typically done using techniques such as grid search or random search.\n",
    "\n",
    "# What is the purpose of the term \"Gaussian Mixture Model\" (GMM)?\n",
    "\n",
    "A Gaussian Mixture Model is a probabilistic model that represents a mixture of multiple Gaussian distributions. It is commonly used for clustering and density estimation tasks.\n",
    "\n",
    "# How does the term \"t-SNE\" (t-Distributed Stochastic Neighbor Embedding) work?\n",
    "\n",
    "t-SNE is a dimensionality reduction technique used for visualizing high-dimensional data in two or three dimensions. It focuses on preserving the pairwise similarities between data points in the lower-dimensional representation.\n",
    "\n",
    "# What is the difference between L1 and L2 regularization?\n",
    "\n",
    "L1 regularization adds a penalty term proportional to the absolute values of the model parameters, encouraging sparsity. L2 regularization adds a penalty term proportional to the squared values of the model parameters, preventing large weights.\n",
    "\n",
    "# Explain the concept of imbalanced datasets in machine learning.\n",
    "\n",
    "Imbalanced datasets occur when the distribution of classes is not equal, leading to a skewed representation of one or more classes. It can pose challenges for classification models, which may become biased towards the majority class.\n",
    "\n",
    "# How does the term \"word2vec\" function in natural language processing?\n",
    "\n",
    "Word2Vec is a technique used to represent words as dense vectors in a continuous vector space. It captures semantic relationships between words based on their co- occurrence patterns in a large corpus of text.\n",
    "\n",
    "# What is the purpose of the term \"churn prediction\" in business analytics?\n",
    "\n",
    "Churn prediction involves forecasting the likelihood of customers discontinuing their use of a product or service. It is crucial for businesses to identify and retain at-risk customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec51459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac17c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
