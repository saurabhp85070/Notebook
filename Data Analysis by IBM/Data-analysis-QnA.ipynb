{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0c3f9e",
   "metadata": {},
   "source": [
    "# How to deal with missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e959bdc",
   "metadata": {},
   "source": [
    "### 1. Remove rows/column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b183312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with any missing values\n",
    "df_cleaned_rows = df.dropna()\n",
    "\n",
    "# Remove columns with any missing values\n",
    "df_cleaned_columns = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3479084",
   "metadata": {},
   "source": [
    "### 3. Imputation:\n",
    "Replace missing values with a suitable estimate. For numerical data, you might use the mean, median, or mode. For categorical data, you might use the most frequent category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values with the mean\n",
    "df_imputed = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef1a65d",
   "metadata": {},
   "source": [
    "### 3. Forward or Backward Fill:\n",
    "\n",
    "For time series data, you might consider using forward fill (`ffill()`) or backward fill (`bfill()`) to fill missing values based on the previous or next observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38da1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill missing values\n",
    "df_forward_filled = df.ffill()\n",
    "\n",
    "# Backward fill missing values\n",
    "df_backward_filled = df.bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954bc8e",
   "metadata": {},
   "source": [
    "### 4. Interpolation:\n",
    "Interpolation methods can be used to estimate missing values based on the values present in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear interpolation\n",
    "df_interpolated = df.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9daa16",
   "metadata": {},
   "source": [
    "### 5. Custom Functions:\n",
    "For more complex situations, you may implement custom functions to fill missing values based on specific business logic or domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182808fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to fill missing values based on specific logic\n",
    "def custom_fill(column):\n",
    "    # Your custom logic here\n",
    "    return filled_column\n",
    "\n",
    "df['column_name'] = custom_fill(df['column_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4438c6",
   "metadata": {},
   "source": [
    "### 6. Handling Categorical Data:\n",
    "For categorical data, you can replace missing values with a new category or use the most frequent category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da21b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing categorical values with a new category\n",
    "df['categorical_column'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# Replace missing categorical values with the most frequent category\n",
    "df['categorical_column'].fillna(df['categorical_column'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405bd179",
   "metadata": {},
   "source": [
    "### 7. Drop Irrelevant Columns:\n",
    "If a column has a high percentage of missing values and is not relevant for analysis, consider dropping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a column with a high percentage of missing values\n",
    "df.drop('column_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a79b7e",
   "metadata": {},
   "source": [
    "### 8. Use Specialized Libraries:\n",
    "Consider using specialized libraries like scikit-learn or fancyimpute for more advanced imputation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c85621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values with the mean using scikit-learn\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed_sklearn = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5b258",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5b73276",
   "metadata": {},
   "source": [
    "## Example of each scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2f4a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A      B    C     D\n",
      "0  1.0    red  0.1  10.0\n",
      "1  2.0   blue  NaN  20.0\n",
      "2  NaN    NaN  0.3  30.0\n",
      "3  4.0  green  0.4   NaN\n",
      "4  5.0    red  0.5  50.0\n",
      "\n",
      "\n",
      "Missing Values:\n",
      "A    1\n",
      "B    1\n",
      "C    1\n",
      "D    1\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "DataFrame after removing rows with missing values:\n",
      "     A    B    C     D\n",
      "0  1.0  red  0.1  10.0\n",
      "4  5.0  red  0.5  50.0\n",
      "\n",
      "\n",
      "DataFrame after removing columns with missing values:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n",
      "\n",
      "\n",
      "DataFrame after imputation with mean:\n",
      "     A      B      C     D\n",
      "0  1.0    red  0.100  10.0\n",
      "1  2.0   blue  0.325  20.0\n",
      "2  3.0    NaN  0.300  30.0\n",
      "3  4.0  green  0.400  27.5\n",
      "4  5.0    red  0.500  50.0\n",
      "\n",
      "\n",
      "DataFrame after forward fill:\n",
      "     A      B    C     D\n",
      "0  1.0    red  0.1  10.0\n",
      "1  2.0   blue  0.1  20.0\n",
      "2  2.0   blue  0.3  30.0\n",
      "3  4.0  green  0.4  30.0\n",
      "4  5.0    red  0.5  50.0\n",
      "\n",
      "\n",
      "DataFrame after linear interpolation:\n",
      "     A      B    C     D\n",
      "0  1.0    red  0.1  10.0\n",
      "1  2.0   blue  0.2  20.0\n",
      "2  3.0    NaN  0.3  30.0\n",
      "3  4.0  green  0.4  40.0\n",
      "4  5.0    red  0.5  50.0\n",
      "\n",
      "\n",
      "DataFrame after custom fill:\n",
      "     A      B    C     D\n",
      "0  1.0    red  0.1  10.0\n",
      "1  2.0   blue  NaN  20.0\n",
      "2 -1.0    NaN  0.3  30.0\n",
      "3  4.0  green  0.4   NaN\n",
      "4  5.0    red  0.5  50.0\n",
      "\n",
      "\n",
      "DataFrame after filling missing categorical values with 'Unknown':\n",
      "     A        B    C     D\n",
      "0  1.0      red  0.1  10.0\n",
      "1  2.0     blue  NaN  20.0\n",
      "2 -1.0  Unknown  0.3  30.0\n",
      "3  4.0    green  0.4   NaN\n",
      "4  5.0      red  0.5  50.0\n",
      "\n",
      "\n",
      "DataFrame after dropping column 'C':\n",
      "     A        B     D\n",
      "0  1.0      red  10.0\n",
      "1  2.0     blue  20.0\n",
      "2 -1.0  Unknown  30.0\n",
      "3  4.0    green   NaN\n",
      "4  5.0      red  50.0\n",
      "\n",
      "\n",
      "DataFrame after imputation using scikit-learn:\n",
      "     A        B     D\n",
      "0  1.0      red  10.0\n",
      "1  2.0     blue  20.0\n",
      "2 -1.0  Unknown  30.0\n",
      "3  4.0    green  27.5\n",
      "4  5.0      red  50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAURAB~1\\AppData\\Local\\Temp/ipykernel_7024/3677410166.py:35: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_imputed = df.fillna(df.mean())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample dataframe with missing values\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': ['red', 'blue', np.nan, 'green', 'red'],\n",
    "    'C': [0.1, np.nan, 0.3, 0.4, 0.5],\n",
    "    'D': [10, 20, 30, np.nan, 50]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 1. Identify Missing Values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2. Remove Rows or Columns\n",
    "df_cleaned_rows = df.dropna()\n",
    "print(\"DataFrame after removing rows with missing values:\")\n",
    "print(df_cleaned_rows)\n",
    "print(\"\\n\")\n",
    "\n",
    "df_cleaned_columns = df.dropna(axis=1)\n",
    "print(\"DataFrame after removing columns with missing values:\")\n",
    "print(df_cleaned_columns)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 3. Imputation\n",
    "df_imputed = df.fillna(df.mean())\n",
    "print(\"DataFrame after imputation with mean:\")\n",
    "print(df_imputed)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 4. Forward or Backward Fill\n",
    "df_forward_filled = df.ffill()\n",
    "print(\"DataFrame after forward fill:\")\n",
    "print(df_forward_filled)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 5. Interpolation\n",
    "df_interpolated = df.interpolate()\n",
    "print(\"DataFrame after linear interpolation:\")\n",
    "print(df_interpolated)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 6. Custom Functions (Assuming a custom function that fills missing values with -1)\n",
    "def custom_fill(column):\n",
    "    return column.fillna(-1)\n",
    "\n",
    "df['A'] = custom_fill(df['A'])\n",
    "print(\"DataFrame after custom fill:\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 7. Handling Categorical Data\n",
    "df['B'].fillna('Unknown', inplace=True)\n",
    "print(\"DataFrame after filling missing categorical values with 'Unknown':\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 8. Drop Irrelevant Columns\n",
    "df.drop('C', axis=1, inplace=True)\n",
    "print(\"DataFrame after dropping column 'C':\")\n",
    "print(df)\n",
    "print(\"\\n\")\n",
    "\n",
    "# 9. Use Specialized Libraries (Scikit-learn) - Handling Numeric and Categorical Columns\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include='number').columns\n",
    "categorical_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "# Impute missing values in numeric columns with mean\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "df[numeric_cols] = numeric_imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Impute missing values in categorical columns with most frequent\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Display the imputed DataFrame\n",
    "print(\"DataFrame after imputation using scikit-learn:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8c607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58c835b9",
   "metadata": {},
   "source": [
    "# What is object datatype?\n",
    "\n",
    "In the context of pandas, when a column in a DataFrame has the data type \"object,\" it usually means that the column contains textual data or a mixture of different data types (e.g., strings, mixed types, or Python objects). The \"object\" data type is a catch-all for columns that don't fit into the more specific data types like int, float, or datetime.\n",
    "\n",
    "You can leave the \"object\" datatype as it is if it suits your analysis or if the nature of the data in that column is inherently text-based or mixed. The \"object\" datatype is a generic and flexible datatype that can accommodate various types of data, including strings and mixed types.\n",
    "\n",
    "However, it's essential to be aware of potential **limitations when working with \"object\" datatype columns:**\n",
    "\n",
    "**Performance:** Operations on columns with \"object\" datatype might be slower than on columns with more specific datatypes like integers or floats. This is because pandas can optimize operations on homogeneous data types more effectively.\n",
    "\n",
    "**Functionality:** Some pandas and NumPy operations may not work as expected on \"object\" datatypes. For example, mathematical operations are generally designed for numerical data types and may not apply directly to \"object\" columns.\n",
    "\n",
    "**Memory Usage:** Columns with the \"object\" datatype can consume more memory than columns with specific datatypes, as each element in an \"object\" column is essentially a reference to a Python object.\n",
    "\n",
    "**If the data in your \"object\" columns consists of text or mixed types, and you don't need to perform extensive numerical or date-based operations on these columns, leaving them as \"object\" might be perfectly fine**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2561bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatype\n",
    "df[['col1', 'col2']].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b0d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8b0e262",
   "metadata": {},
   "source": [
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': ['red', 'blue', np.nan, 'green', 'red'],\n",
    "    'C': [0.1, np.nan, 0.3, 0.4, 0.5],\n",
    "    'D': [10, 20, 30, np.nan, 50]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6863fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>green</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>red</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B    C     D\n",
       "0  1.0    red  0.1  10.0\n",
       "1  2.0   blue  NaN  20.0\n",
       "2  NaN    NaN  0.3  30.0\n",
       "3  4.0  green  0.4   NaN\n",
       "4  5.0    red  0.5  50.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': ['red', 'blue', np.nan, 'green', 'red'],\n",
    "    'C': [0.1, np.nan, 0.3, 0.4, 0.5],\n",
    "    'D': [10, 20, 30, np.nan, 50]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b00459f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['A'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SAURAB~1\\AppData\\Local\\Temp/ipykernel_7024/2837246697.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4899\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4900\u001b[0m         \"\"\"\n\u001b[1;32m-> 4901\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4902\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4903\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4145\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4147\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4180\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4181\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4182\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4183\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['A'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop('A', axis=0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e188186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
